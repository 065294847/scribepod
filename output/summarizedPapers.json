{
  "LAMBADA: Backward Chaining for Automated Reasoning in Natural Language": [
    "- This work focuses on performing automated reasoning over facts, which are natural language assertions that may or may not be grounded in reality",
    "- A rule is a natural language statement that can be written in the form \"If P then Q\", where P is the antecedent and Q is the consequent",
    "- A theory consists of a set of facts and rules",
    "- Backward chaining (BC) is a strategy for reasoning that starts from a goal and breaks it down into sub-goals based on rules that apply to it, until the sub-goals can be proved or disproved based on the facts or no more rules can be applied",
    "- The outcome of BC for a goal can be either proved, disproved, or unknown",
    "- BC is implemented using four natural language processing (NLP) modules: Fact Check, Rule Selection, Goal Decomposition, and Sign Agreement",
    "- The Fact Check module verifies if a goal can be proved or disproved based on the facts",
    "- The Rule Selection module selects the rules that can be applied to a goal based on unification in logic",
    "- The Goal Decomposition module breaks down a goal into sub-goals based on the selected rules",
    "- The Sign Agreement module checks that the signs of the sub-goals match the sign of the original goal (i.e. if the original goal is a positive statement, all sub-goals should also be positive statements)",
    "- The results of the \\algo\\ and baseline models are shown in Figures~\\ref{fig:proofwriter} and \\ref{fig:pronto}",
    "- \\algo\\ outperforms the other two baselines, especially on ProofWriter-PUD and higher depths of PrOntoQA",
    "- \\algo's backward chaining method is more effective than the forward chaining used in SI",
    "- CoT struggles with handling unknown labels and tends to over-predict \\disproved\\ or \\unk\\ at higher depths",
    "- \\algo\\ mostly produces correct chains when it correctly predicts the label, while CoT only produces correct chains 28% of the time on Depth-5 of ProofWriter-PD",
    "- The main source of error for CoT is hallucinating rules or facts, followed by not understanding conjunction and making invalid derivations",
    "- Spurious correlations in ProofWriter-PD may contribute to CoT's high accuracy on that dataset",
    "- The intermediate modules in SI and \\algo\\ are not affected by spurious correlations",
    "- The proof accuracy of \\algo's individual components is similar to its overall accuracy, indicating that all components are contributing to its performance.",
    "- \\algo\\ is tested on an example in ProofWriter and correctly predicts that the goal is disproved",
    "- \\algo\\ performs cycle matching to avoid repeating searches, but currently only does exact matches",
    "- \\algo\\ calls \\module{Goal Decomposition} module and breaks a goal into sub-goals",
    "- \\module{Fact Check} and \\module{Rule Selection} modules are called on the sub-goals",
    "- \\module{Goal Decomposition} is called on the sub-goals and the process repeats until the maximum depth is reached or a sub-goal is proved",
    "- If a sub-goal is proved, it is stored in the cache so that it can be retrieved later to avoid repeating the search",
    "- \\algo\\ also calls the \\module{Sign Agreement} module and checks that the signs of the rules and sub-goals agree, except for the first rule selected",
    "- \\algo\\ is tested on a modified version of the ProofWriter dataset where entity names and animal names are replaced with new names",
    "- \\algo\\ performs well on this modified dataset, showing that it is not highly sensitive to lexical changes",
    "- The search trace of the model called \"Algo\" was analyzed on an example in the \"ProofWriter\" dataset (Depth-5)",
    "- The model correctly predicted that the goal was disproved based on the theory",
    "- The model currently only does cycle matching for exact matches, so it continues the search trace even if the sub-goal is the negation of the root goal",
    "- The \"Goal Decomposition\" module breaks the sub-goal into two parts: \"Dave is blue\" and \"Dave is cold\"",
    "- \"Fact Check\" fails on \"Dave is blue,\" and \"Rule Selection\" selects \"Rule 5\"",
    "- \"Goal Decomposition\" breaks the sub-goal \"Dave is cold\" into smaller sub-goals, but \"Fact Check\" fails and the maximum depth is reached, so the algorithm stops expanding that branch",
    "- \"Fact Check\" also fails on the right branch for the sub-goal \"Dave is blue,\" and \"Rule Selection\" selects \"Rule 8\"",
    "- \"Goal Decomposition\" produces two sub-goals: \"Dave is kind\" and \"Dave is young\"",
    "- \"Fact Check\" fails on \"Dave is kind,\" and \"Rule Selection\" selects \"Rule 4\"",
    "- \"Goal Decomposition\" produces two sub-goals: \"Dave is white\" and \"Dave is young\"",
    "- \"Fact Check\" succeeds in proving both \"Dave is white\" and \"Dave is young\"",
    "- \"Sign Agreement\" module is called for rules on the right branch and finds that the sign of the rule and sub-goals always agree, except for the first rule (Rule 3)",
    "- A new test was created for \"ProofWriter-PUD\" with modified tokens that do not appear in demonstration examples",
    "- The model's performance was compared to two baselines on this modified test set",
    "- The model's performance was also compared to the baselines on a test set for \"PrOntoQA\" (Depth-5)",
    "- Confusion matrices for the model and baselines on both test sets are provided"
  ]
}